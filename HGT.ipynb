{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cd285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import HGTConv\n",
    "from startup_data_set import *\n",
    "from PredictorClasses import *\n",
    "from CustomMetrics import *\n",
    "from CustomUtilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24b33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = COMP4222Dataset_hetero()\n",
    "g = graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'investor': 7594, 'startup': 17852},\n",
      "      num_edges={('investor', 'i_s', 'startup'): 45621},\n",
      "      metagraph=[('investor', 'startup', 'i_s')])\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aedefd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_g = construct_negative_hetero_graph(g,1,(\"investor\",\"raise\",\"startup\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b575d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_feats = g.nodes['investor'].data['feat']\n",
    "startup_feats = g.nodes['startup'].data['feat']\n",
    "node_features = {'investor': investor_feats, \n",
    "                 'startup': startup_feats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0eec6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g, test_g, valid_g = generate_train_test_valid_hetero_graph(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "adadbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_features_size,\n",
    "                 head_size,\n",
    "                 num_heads,\n",
    "                 num_ntypes,\n",
    "                 num_etypes,\n",
    "                 dropout=0.2,\n",
    "                 use_norm=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = HGTConv(in_features_size, head_size, num_heads, num_ntypes,num_etypes,dropout,use_norm)\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, neg_g, x, ntype, etype):\n",
    "        h = self.conv(g, x, ntype, etype)\n",
    "        return self.pred(g, h, etype), self.pred(neg_g, h, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ad0b6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        # h contains the node representations for each node type computed from\n",
    "        # the GNN defined in the previous section (Section 5.1).\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f6d9c3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'investor': 7594, 'startup': 21483},\n",
      "      num_edges={('investor', 'raise', 'startup'): 48787},\n",
      "      metagraph=[('investor', 'startup', 'raise')])\n",
      "{'_ID': tensor([    0,     1,     2,  ..., 21480, 21481, 21482]), '_TYPE': tensor([0, 0, 0,  ..., 1, 1, 1])}\n",
      "torch.Size([48787])\n",
      "torch.Size([29077])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [111], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     34\u001b[0m     negative_graph \u001b[38;5;241m=\u001b[39m construct_negative_hetero_graph(train_g, k, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvestor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 36\u001b[0m     pos_score, neg_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minvestor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43mntype\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m compute_loss(pos_score, neg_score)\n\u001b[0;32m     39\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [106], line 15\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, g, neg_g, x, ntype, etype)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, neg_g, x, ntype, etype):\n\u001b[1;32m---> 15\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred(g, h, etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred(neg_g, h, etype)\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\hgtconv.py:128\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[1;34m(self, g, x, ntype, etype, presorted)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpresorted \u001b[38;5;241m=\u001b[39m presorted\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mlocal_scope():\n\u001b[1;32m--> 128\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresorted\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size)\n\u001b[0;32m    129\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_q(x, ntype, presorted)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size)\n\u001b[0;32m    130\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_v(x, ntype, presorted)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size)\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\dgl\\nn\\pytorch\\linear.py:174\u001b[0m, in \u001b[0;36mTypedLinear.forward\u001b[1;34m(self, x, x_type, sorted_by_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segment_mm(x, w, seglen_a\u001b[38;5;241m=\u001b[39mseglen)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\dgl\\ops\\gather_mm.py:36\u001b[0m, in \u001b[0;36mgather_mm\u001b[1;34m(a, b, idx_b)\u001b[0m\n\u001b[0;32m     34\u001b[0m sorted_idx_b, perm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(idx_b)\n\u001b[0;32m     35\u001b[0m _, rev_perm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(perm)\n\u001b[1;32m---> 36\u001b[0m sorted_a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m pos_l \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msearchsorted(sorted_idx_b, torch\u001b[38;5;241m.\u001b[39marange(R, device\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     38\u001b[0m pos_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pos_l[\u001b[38;5;241m1\u001b[39m:], torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mlen\u001b[39m(idx_b)], device\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mdevice)])\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "print(train_g)\n",
    "t_g = dgl.to_homogeneous(train_g)\n",
    "k = 5\n",
    "num_etypes = int(len(train_g.ntypes))\n",
    "num_ntypes = int(len(train_g.etypes))\n",
    "# in_features_size = train_g.nodes[\"investor\"].data[\"feat\"].shape[1]\n",
    "print(t_g.ndata)\n",
    "num_heads = 5\n",
    "head_size = in_features_size//num_heads\n",
    "\n",
    "model = Model(in_features_size, \n",
    "              head_size, \n",
    "              num_heads, \n",
    "              int(len(train_g.ntypes)),\n",
    "              int(len(train_g.etypes)))\n",
    "\n",
    "investor_feats = g.nodes['investor'].data['feat']\n",
    "startup_feats = g.nodes['startup'].data['feat']\n",
    "node_features = {'investor': investor_feats, 'startup': startup_feats}\n",
    "\n",
    "\n",
    "etype = torch.tensor([i % num_etypes for i in range(train_g.num_edges())])\n",
    "ntype = torch.tensor([i % num_ntypes for i in range(train_g.num_nodes())])\n",
    "\n",
    "print(etype.shape)\n",
    "print(ntype.shape)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(10):\n",
    "    negative_graph = construct_negative_hetero_graph(train_g, k, (\"investor\",\"raise\",\"startup\"))\n",
    "    \n",
    "    pos_score, neg_score = model(t_g, negative_graph, train_g.nodes[\"investor\"].data[\"feat\"],etype,ntype )\n",
    "    \n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7de8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_ws",
   "language": "python",
   "name": "gnn_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
