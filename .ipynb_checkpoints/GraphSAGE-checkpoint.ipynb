{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef4235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import conv as dgl_conv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from startup_data_set import COMP4222Dataset\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ceb2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=25446, num_edges=45621,\n",
      "      ndata_schemes={'feat': Scheme(shape=(221,), dtype=torch.float64), 'label': Scheme(shape=(), dtype=torch.float32)}\n",
      "      edata_schemes={'feat': Scheme(shape=(26,), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "dataset = COMP4222Dataset()\n",
    "graph = dataset[0]\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9c3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = graph.ndata['feat'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e99194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = graph.edges()\n",
    "# give id for all edges then permutation\n",
    "eids = np.arange(graph.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "# use 10% as test set\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = graph.number_of_edges() - test_size\n",
    "\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "\n",
    "#use sparse matrix to save memory\n",
    "# ,shape = (torch.max(v)+1,torch.max(v)+1)\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(torch.max(u)+1,torch.max(v)+1)\n",
    "neg_u, neg_v = np.where(adj_neg != 0) # negative edge, we don't have edge\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), graph.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797f4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe58bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(graph, eids[:test_size])\n",
    "train_g = dgl.add_self_loop(train_g)\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=graph.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=graph.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=graph.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=graph.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "171f3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 out_dim,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator_type):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input layer\n",
    "        self.layers.append(dgl_conv.SAGEConv(in_feats, n_hidden, aggregator_type,\n",
    "                                         feat_drop=dropout, activation=activation))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(dgl_conv.SAGEConv(n_hidden, n_hidden, aggregator_type,\n",
    "                                             feat_drop=dropout, activation=activation))\n",
    "        # output layer\n",
    "        self.layers.append(dgl_conv.SAGEConv(n_hidden, out_dim, aggregator_type,\n",
    "                                         feat_drop=dropout, activation=None))\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        h = features.float()\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h).float()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ce225f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_hidden = 64\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "aggregator_type = 'mean'\n",
    "\n",
    "gconv_model = GraphSAGEModel(in_feats,\n",
    "                             n_hidden,\n",
    "                             n_hidden,\n",
    "                             n_layers,\n",
    "                             F.relu,\n",
    "                             dropout,\n",
    "                             aggregator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1680bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c945ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 9.045723915100098\n",
      "In epoch 5, loss: 0.8431828022003174\n",
      "In epoch 10, loss: 0.6943535208702087\n",
      "In epoch 15, loss: 0.6908046007156372\n",
      "In epoch 20, loss: 0.6906868815422058\n",
      "In epoch 25, loss: 0.6911425590515137\n",
      "In epoch 30, loss: 0.6902279257774353\n",
      "In epoch 35, loss: 0.6895298361778259\n",
      "In epoch 40, loss: 0.68839031457901\n",
      "In epoch 45, loss: 0.6869620680809021\n",
      "In epoch 50, loss: 0.6846441626548767\n",
      "In epoch 55, loss: 0.6784398555755615\n",
      "In epoch 60, loss: 0.6762485504150391\n",
      "In epoch 65, loss: 0.6652789115905762\n",
      "In epoch 70, loss: 0.6603643894195557\n",
      "In epoch 75, loss: 0.6487939953804016\n",
      "In epoch 80, loss: 0.640209436416626\n",
      "In epoch 85, loss: 0.6273946762084961\n",
      "In epoch 90, loss: 0.6154678463935852\n",
      "In epoch 95, loss: 0.6054980754852295\n",
      "In epoch 100, loss: 0.5993087887763977\n",
      "In epoch 105, loss: 0.5985466241836548\n",
      "In epoch 110, loss: 0.5821447372436523\n",
      "In epoch 115, loss: 0.581139326095581\n",
      "In epoch 120, loss: 0.5762310028076172\n",
      "In epoch 125, loss: 0.5707046985626221\n",
      "In epoch 130, loss: 0.5681790709495544\n",
      "In epoch 135, loss: 0.5606666207313538\n",
      "In epoch 140, loss: 0.561669111251831\n",
      "In epoch 145, loss: 0.559440553188324\n",
      "AUC 0.8545100568695404\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(gconv_model.parameters(), pred.parameters()), lr=0.01)\n",
    "for e in range(150):\n",
    "    # forward\n",
    "    h = gconv_model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
