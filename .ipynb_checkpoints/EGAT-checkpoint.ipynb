{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0cd285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn import EGATConv\n",
    "from startup_data_set import *\n",
    "from PredictorClasses import *\n",
    "from CustomMetrics import *\n",
    "from CustomUtilities import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24b33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = COMP4222Dataset()\n",
    "g = graph[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0be2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  203,   231,   232,  ...,  5030,  8850, 15490])\n",
      "tensor([17852, 17852, 17852,  ..., 25444, 25444, 25445])\n"
     ]
    }
   ],
   "source": [
    "u,v=g.edges()\n",
    "print(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8eeda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata[\"feat\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070d72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g, train_pos_g, val_pos_g, test_pos_g = generate_pos_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a08a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_g, val_neg_g, test_neg_g = generate_neg_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7b9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g, train_pos_g, val_pos_g, test_pos_g = train_g.to(device), train_pos_g.to(device), val_pos_g, test_pos_g.to(device)\n",
    "train_neg_g, val_neg_g, test_neg_g = train_neg_g.to(device), val_neg_g.to(device), test_neg_g.to(device)\n",
    "num_nodes = g.num_nodes\n",
    "num_edges = g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24665b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "egat_model = EGATConv(in_node_feats = train_g.ndata[\"feat\"].shape[1],\n",
    "                in_edge_feats = train_g.edata[\"feat\"].shape[1],\n",
    "                out_node_feats = 16,\n",
    "                out_edge_feats = 16,\n",
    "                num_heads = 3).to(device)\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(2*h_feats , h_feats).to(torch.float32)\n",
    "        self.W2 = nn.Linear(h_feats, 1).to(torch.float32)\n",
    "\n",
    "    # concat the source and destination node, use mlp to predict the score\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1).to(torch.float32)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h.to(torch.float32)\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "\n",
    "pred = MLPPredictor(48)\n",
    "early_stopping = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "854e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Train loss: 0.695 \t Val loss: 0.694 \t Train AUC: 0.542 \t Val AUC: 0.586\n",
      "Epoch: 10 \t Train loss: 0.684 \t Val loss: 0.685 \t Train AUC: 0.682 \t Val AUC: 0.656\n",
      "Epoch: 20 \t Train loss: 0.675 \t Val loss: 0.677 \t Train AUC: 0.697 \t Val AUC: 0.669\n",
      "Epoch: 30 \t Train loss: 0.664 \t Val loss: 0.667 \t Train AUC: 0.717 \t Val AUC: 0.687\n",
      "Epoch: 40 \t Train loss: 0.646 \t Val loss: 0.653 \t Train AUC: 0.742 \t Val AUC: 0.708\n",
      "Epoch: 50 \t Train loss: 0.622 \t Val loss: 0.634 \t Train AUC: 0.77 \t Val AUC: 0.73\n",
      "Epoch: 60 \t Train loss: 0.588 \t Val loss: 0.607 \t Train AUC: 0.803 \t Val AUC: 0.758\n",
      "Epoch: 70 \t Train loss: 0.537 \t Val loss: 0.565 \t Train AUC: 0.851 \t Val AUC: 0.802\n",
      "Epoch: 80 \t Train loss: 0.456 \t Val loss: 0.497 \t Train AUC: 0.912 \t Val AUC: 0.864\n",
      "Epoch: 90 \t Train loss: 0.368 \t Val loss: 0.422 \t Train AUC: 0.943 \t Val AUC: 0.9\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "train_AUC, val_AUC = [], []\n",
    "stop = 0\n",
    "ep = 100\n",
    "optimizer = torch.optim.Adam(itertools.chain(egat_model.parameters(), pred.parameters()))\n",
    "\n",
    "for e in range(ep):\n",
    "    # forward\n",
    "    h, efeat= egat_model(train_g, train_g.ndata['feat'].to(torch.float32), train_g.edata[\"feat\"].to(torch.float32))\n",
    "    h, efeat = h.flatten(1) , efeat.flatten(1)\n",
    "    pos_score = pred(train_pos_g,h)\n",
    "    neg_score = pred(train_neg_g,h)\n",
    "    \n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    train_loss.append(loss.item())\n",
    "    train_AUC.append(compute_auc(pos_score, neg_score))\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    v_pos_score = pred(val_pos_g, h)\n",
    "    v_neg_score = pred(val_neg_g, h)\n",
    "    v_loss = compute_loss(v_pos_score, v_neg_score)\n",
    "    val_loss.append(v_loss.item())\n",
    "    val_AUC.append(compute_auc(v_pos_score, v_neg_score))\n",
    "\n",
    "    #verbose\n",
    "    if e % 10 == 0:\n",
    "        print('Epoch: {} \\t Train loss: {} \\t Val loss: {} \\t Train AUC: {} \\t Val AUC: {}'.format(e, round(loss.item(), 3), round(v_loss.item(), 3), round(train_AUC[-1],3), round(val_AUC[-1], 3)))\n",
    "\n",
    "\n",
    "    # early stopping\n",
    "    if e > 10:\n",
    "        if v_loss.item() > sum(val_loss[-5:])/5:\n",
    "            stop += 1\n",
    "        else: \n",
    "            stop = 0\n",
    "        if stop >= early_stopping:\n",
    "            print(\"Early Stopped at Epoch {}\".format(e))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cb584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_ws",
   "language": "python",
   "name": "gnn_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
