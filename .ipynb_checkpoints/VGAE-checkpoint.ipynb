{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cc8def",
   "metadata": {},
   "source": [
    "# VGAE Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7b749",
   "metadata": {},
   "source": [
    "```\n",
    "@article{kipf2016variational,\n",
    "  title={Variational Graph Auto-Encoders},\n",
    "  author={Kipf, Thomas N and Welling, Max},\n",
    "  journal={NIPS Workshop on Bayesian Deep Learning},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c48cb",
   "metadata": {
    "id": "d86c48cb"
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef4235b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eef4235b",
    "outputId": "8ae5d48b-a3a2-480b-b6fc-6246acc49452"
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import conv as dgl_conv\n",
    "from utils.startup_data_set import COMP4222Dataset_hetero\n",
    "from utils.PredictorClasses import *\n",
    "from utils.CustomMetrics import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5147a43",
   "metadata": {
    "id": "b5147a43"
   },
   "source": [
    "### Hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13e5bde2",
   "metadata": {
    "id": "13e5bde2"
   },
   "outputs": [],
   "source": [
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Hyperparameters\n",
    "n_hidden = 32\n",
    "output_dim = 16\n",
    "\n",
    "early_stopping = 5\n",
    "ep = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6446e8",
   "metadata": {
    "id": "1e6446e8"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8ceb2eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ceb2eb",
    "outputId": "68bd8ee4-2af3-4d59-96fd-424af660f5b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=25446, num_edges=45621,\n",
       "      ndata_schemes={'feat': Scheme(shape=(221,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={'feat': Scheme(shape=(23,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = COMP4222Dataset_hetero()[0]\n",
    "graph = dgl.to_homogeneous(graph,ndata=['feat'],edata=['feat'])\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e82188",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7e82188",
    "outputId": "5caebb33-76e8-4207-9a6a-4c6c6968baad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feats = graph.ndata['feat'].shape[1]\n",
    "in_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76e323",
   "metadata": {
    "id": "7e76e323"
   },
   "source": [
    "## Generate Postitve Graph and Negative Graph with Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b21ea8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b21ea8e",
    "outputId": "94bed0eb-bd65-4d06-dd06-20f31a05617e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=25446, num_edges=61943,\n",
       "      ndata_schemes={'feat': Scheme(shape=(221,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={'feat': Scheme(shape=(23,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.CustomUtilities import generate_neg_graph, generate_pos_graph\n",
    "train_g, train_pos_g, val_pos_g, test_pos_g = \\\n",
    "    generate_pos_graph(graph, val_ratio, test_ratio)\n",
    "\n",
    "train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfe9889",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dfe9889",
    "outputId": "fa097060-48c8-4f7f-ef43-82ebb432455f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=25446, num_edges=36497,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_g, val_neg_g, test_neg_g = \\\n",
    "    generate_neg_graph(graph, val_ratio, test_ratio)\n",
    "\n",
    "train_neg_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38657b8",
   "metadata": {
    "id": "e38657b8"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4f954",
   "metadata": {
    "id": "c3a4f954"
   },
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171f3f4d",
   "metadata": {
    "id": "171f3f4d"
   },
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "\n",
    "class VGAEModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden1_dim, hidden2_dim):\n",
    "        super(VGAEModel, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "\n",
    "        layers = [\n",
    "            GraphConv(\n",
    "                self.in_dim,\n",
    "                self.hidden1_dim,\n",
    "                activation=F.relu,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "        ]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def encoder(self, g, features):\n",
    "        h = self.layers[0](g, features)\n",
    "        self.mean = self.layers[1](g, h)\n",
    "        self.log_std = self.layers[2](g, h)\n",
    "        gaussian_noise = torch.randn(features.size(0), self.hidden2_dim).to(\n",
    "            device\n",
    "        )\n",
    "        sampled_z = self.mean + gaussian_noise * torch.exp(self.log_std).to(\n",
    "            device\n",
    "        )\n",
    "        return sampled_z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        adj_rec = nn.ReLU()(torch.matmul(z, z.t()))\n",
    "        return adj_rec\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        z = self.encoder(g, features)\n",
    "        adj_rec = self.decoder(z)\n",
    "        return adj_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce225f9",
   "metadata": {
    "id": "5ce225f9"
   },
   "outputs": [],
   "source": [
    "vgae_model = VGAEModel(\n",
    "    in_feats,\n",
    "    n_hidden,\n",
    "    output_dim\n",
    ").to(device)\n",
    "\n",
    "pred = MLPPredictor(int(50892/2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaf5ef5f",
   "metadata": {
    "id": "aaf5ef5f"
   },
   "outputs": [],
   "source": [
    "vgae_model = vgae_model.to(device)\n",
    "pred = pred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Dn9-qjcQUCqx",
   "metadata": {
    "id": "Dn9-qjcQUCqx"
   },
   "outputs": [],
   "source": [
    "train_g = train_g.to(device)\n",
    "train_g.ndata['feat'] = train_g.ndata['feat'].float().to(device)\n",
    "train_pos_g = train_pos_g.to(device)\n",
    "train_neg_g = train_neg_g.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ceeab3",
   "metadata": {
    "id": "88ceeab3"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c945ab1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c945ab1f",
    "outputId": "e0966adf-2e68-4345-d22a-8bd468b73a3b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3714810648 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ep):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     h \u001b[38;5;241m=\u001b[39m vgae_model(train_g, train_g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 13\u001b[0m     pos_score \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pos_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m     neg_score \u001b[38;5;241m=\u001b[39m pred(train_neg_g\u001b[38;5;241m.\u001b[39mto(device), h)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m compute_loss(pos_score, neg_score)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\project\\COMP-4222-Project\\utils\\PredictorClasses.py:37\u001b[0m, in \u001b[0;36mMLPPredictor.forward\u001b[1;34m(self, g, h)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mlocal_scope():\n\u001b[0;32m     36\u001b[0m     g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_edges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\dgl\\heterograph.py:4460\u001b[0m, in \u001b[0;36mDGLHeteroGraph.apply_edges\u001b[1;34m(self, func, edges, etype, inplace)\u001b[0m\n\u001b[0;32m   4458\u001b[0m     edata \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39minvoke_gsddmm(g, func)\n\u001b[0;32m   4459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4460\u001b[0m     edata \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_edge_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mnumber_of_etypes() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_e_repr(etid, eid, edata)\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\dgl\\core.py:85\u001b[0m, in \u001b[0;36minvoke_edge_udf\u001b[1;34m(graph, eid, etype, func, orig_eid)\u001b[0m\n\u001b[0;32m     82\u001b[0m dstdata \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_node_frames[dtid]\u001b[38;5;241m.\u001b[39msubframe(v)\n\u001b[0;32m     83\u001b[0m ebatch \u001b[38;5;241m=\u001b[39m EdgeBatch(graph, eid \u001b[38;5;28;01mif\u001b[39;00m orig_eid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m orig_eid,\n\u001b[0;32m     84\u001b[0m                    etype, srcdata, edata, dstdata)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mebatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\project\\COMP-4222-Project\\utils\\PredictorClasses.py:32\u001b[0m, in \u001b[0;36mMLPPredictor.apply_edges\u001b[1;34m(self, edges)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_edges\u001b[39m(\u001b[38;5;28mself\u001b[39m, edges):\n\u001b[0;32m     31\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edges\u001b[38;5;241m.\u001b[39msrc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m], edges\u001b[38;5;241m.\u001b[39mdst[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m]], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)}\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Dennis\\ust\\year3_fall_sem\\COMP4222\\gnn_ws\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3714810648 bytes."
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import gc\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "train_AUC, val_AUC = [], []\n",
    "stop = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(vgae_model.parameters(), pred.parameters()), lr=0.05)\n",
    "\n",
    "for e in range(ep):\n",
    "    # forward\n",
    "    h = vgae_model(train_g, train_g.ndata['feat']).to(device)\n",
    "    pos_score = pred(train_pos_g.to(device), h).to(device)\n",
    "    neg_score = pred(train_neg_g.to(device), h).to(device)\n",
    "    loss = compute_loss(pos_score, neg_score).to(device)\n",
    "    train_loss.append(loss.item())\n",
    "    train_AUC.append(compute_auc(pos_score, neg_score))\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    v_pos_score = pred(val_pos_g.to(device), h.to(device))\n",
    "    v_neg_score = pred(val_neg_g.to(device), h.to(device))\n",
    "    v_loss = compute_loss(v_pos_score.to(device), v_neg_score.to(device)).to(device)\n",
    "    val_loss.append(v_loss.item())\n",
    "    val_AUC.append(compute_auc(v_pos_score, v_neg_score))\n",
    "\n",
    "    #verbose\n",
    "    if e % 1 == 0:\n",
    "        print('Epoch: {} \\t Train loss: {} \\t Val loss: {} \\t Train AUC: {} \\t Val AUC: {}'.format(e, round(loss.item(), 3), round(v_loss.item(), 3), round(train_AUC[-1],3), round(val_AUC[-1], 3)))\n",
    "\n",
    "    # early stopping\n",
    "    if e > 10:\n",
    "        if v_loss.item() > sum(val_loss[-5:])/5:\n",
    "            stop += 1\n",
    "        else: \n",
    "            stop = 0\n",
    "        if stop >= early_stopping:\n",
    "            print(\"Early Stopped at Epoch {}\".format(e))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25daee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa25daee",
    "outputId": "8df5f0b2-5941-4ff4-bc7b-5af354fb75f3"
   },
   "outputs": [],
   "source": [
    "# testing AUC\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g.to(device), h)\n",
    "    neg_score = pred(test_neg_g.to(device), h)\n",
    "    print('AUC:', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdf7c9",
   "metadata": {
    "id": "9fbdf7c9"
   },
   "source": [
    "### Result Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7e9cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "dbe7e9cd",
    "outputId": "c7066025-7295-4cf0-c439-e2203a21ad58"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_loss[60:], label='training loss')\n",
    "plt.plot(val_loss[60:], label = 'validation loss')\n",
    "fig.suptitle('VGAE Loss Plot')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db07e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "85db07e4",
    "outputId": "03b2a6ff-afbb-49ab-9d21-17485d3b70f7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_AUC, label='training AUC')\n",
    "plt.plot(val_AUC, label = 'validation AUC')\n",
    "fig.suptitle('VGAE AUC Plot')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda238182c1de36151cdce09aa997c6697b1a1e480bed704816dfcebedb6bbfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
