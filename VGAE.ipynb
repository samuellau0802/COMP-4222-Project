{
    "cells": [{
            "cell_type": "markdown",
            "id": "d86c48cb",
            "metadata": {
                "id": "d86c48cb"
            },
            "source": [
                "## Import Library"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "23db09bb",
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\", category=UserWarning) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "eef4235b",
            "metadata": {
                "id": "eef4235b"
            },
            "outputs": [],
            "source": [
                "import dgl\n",
                "import torch\n",
                "import itertools\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from dgl.nn.pytorch import conv as dgl_conv\n",
                "from startup_data_set import COMP4222Dataset_hetero\n",
                "from PredictorClasses import *\n",
                "from CustomMetrics import *\n",
                "from sklearn.metrics import roc_auc_score\n",
                "import matplotlib.pyplot as plt\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "97ba3dc4",
            "metadata": {
                "id": "97ba3dc4",
                "outputId": "737d2c0b-16a9-44c1-a660-d8ffd2202984"
            },
            "outputs": [{
                "data": {
                    "text/plain": [
                        "device(type='cuda')"
                    ]
                },
                "execution_count": 2,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "device"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5147a43",
            "metadata": {
                "id": "b5147a43"
            },
            "source": [
                "### Hypermeters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "13e5bde2",
            "metadata": {
                "id": "13e5bde2"
            },
            "outputs": [],
            "source": [
                "val_ratio = 0.1\n",
                "test_ratio = 0.1\n",
                "\n",
                "# Hyperparameters\n",
                "n_hidden = 32\n",
                "output_dim = 16\n",
                "\n",
                "early_stopping = 10\n",
                "ep = 100"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e6446e8",
            "metadata": {
                "id": "1e6446e8"
            },
            "source": [
                "## Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "f8ceb2eb",
            "metadata": {
                "id": "f8ceb2eb",
                "outputId": "ececbf2a-f57c-4dc2-f94c-0a5e527cdb94"
            },
            "outputs": [{
                "data": {
                    "text/plain": [
                        "Graph(num_nodes=25446, num_edges=45621,\n",
                        "      ndata_schemes={'feat': Scheme(shape=(221,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)}\n",
                        "      edata_schemes={'feat': Scheme(shape=(23,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})"
                    ]
                },
                "execution_count": 4,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "graph = COMP4222Dataset_hetero()[0]\n",
                "graph = dgl.to_homogeneous(graph,ndata=['feat'],edata=['feat'])\n",
                "graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "b7e82188",
            "metadata": {
                "id": "b7e82188",
                "outputId": "7a598391-99cd-413c-9b6a-2c7f5c112ce3"
            },
            "outputs": [{
                "data": {
                    "text/plain": [
                        "221"
                    ]
                },
                "execution_count": 5,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "in_feats = graph.ndata['feat'].shape[1]\n",
                "in_feats"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7e76e323",
            "metadata": {
                "id": "7e76e323"
            },
            "source": [
                "## Generate Postitve Graph and Negative Graph with Spliting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "3b21ea8e",
            "metadata": {
                "id": "3b21ea8e",
                "outputId": "b400e7f3-69b2-4202-8fe3-61448f1a7e73"
            },
            "outputs": [{
                "data": {
                    "text/plain": [
                        "Graph(num_nodes=25446, num_edges=61943,\n",
                        "      ndata_schemes={'feat': Scheme(shape=(221,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)}\n",
                        "      edata_schemes={'feat': Scheme(shape=(23,), dtype=torch.float64), '_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})"
                    ]
                },
                "execution_count": 6,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "from CustomUtilities import generate_neg_graph, generate_pos_graph\n",
                "train_g, train_pos_g, val_pos_g, test_pos_g = \\\n",
                "    generate_pos_graph(graph, val_ratio, test_ratio)\n",
                "\n",
                "train_g"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "8dfe9889",
            "metadata": {
                "id": "8dfe9889",
                "outputId": "dfbdad04-abca-410a-9efb-2274e89f661c"
            },
            "outputs": [{
                "data": {
                    "text/plain": [
                        "Graph(num_nodes=25446, num_edges=36497,\n",
                        "      ndata_schemes={}\n",
                        "      edata_schemes={})"
                    ]
                },
                "execution_count": 7,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "train_neg_g, val_neg_g, test_neg_g = \\\n",
                "    generate_neg_graph(graph, val_ratio, test_ratio)\n",
                "\n",
                "train_neg_g"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e38657b8",
            "metadata": {
                "id": "e38657b8"
            },
            "source": [
                "## Model Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3a4f954",
            "metadata": {
                "id": "c3a4f954"
            },
            "source": [
                "### Model Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "171f3f4d",
            "metadata": {
                "id": "171f3f4d"
            },
            "outputs": [],
            "source": [
                "from dgl.nn.pytorch import GraphConv\n",
                "\n",
                "\n",
                "class VGAEModel(nn.Module):\n",
                "    def __init__(self, in_dim, hidden1_dim, hidden2_dim):\n",
                "        super(VGAEModel, self).__init__()\n",
                "        self.in_dim = in_dim\n",
                "        self.hidden1_dim = hidden1_dim\n",
                "        self.hidden2_dim = hidden2_dim\n",
                "\n",
                "        layers = [\n",
                "            GraphConv(\n",
                "                self.in_dim,\n",
                "                self.hidden1_dim,\n",
                "                activation=F.relu,\n",
                "                allow_zero_in_degree=True,\n",
                "            ),\n",
                "            GraphConv(\n",
                "                self.hidden1_dim,\n",
                "                self.hidden2_dim,\n",
                "                activation=lambda x: x,\n",
                "                allow_zero_in_degree=True,\n",
                "            ),\n",
                "            GraphConv(\n",
                "                self.hidden1_dim,\n",
                "                self.hidden2_dim,\n",
                "                activation=lambda x: x,\n",
                "                allow_zero_in_degree=True,\n",
                "            ),\n",
                "        ]\n",
                "        self.layers = nn.ModuleList(layers)\n",
                "\n",
                "    def encoder(self, g, features):\n",
                "        h = self.layers[0](g, features)\n",
                "        self.mean = self.layers[1](g, h)\n",
                "        self.log_std = self.layers[2](g, h)\n",
                "        gaussian_noise = torch.randn(features.size(0), self.hidden2_dim).to(\n",
                "            device\n",
                "        )\n",
                "        sampled_z = self.mean + gaussian_noise * torch.exp(self.log_std).to(\n",
                "            device\n",
                "        )\n",
                "        return sampled_z\n",
                "\n",
                "    def decoder(self, z):\n",
                "        adj_rec = nn.ReLU()(torch.matmul(z, z.t()))\n",
                "        return adj_rec\n",
                "\n",
                "    def forward(self, g, features):\n",
                "        z = self.encoder(g, features)\n",
                "        adj_rec = self.decoder(z)\n",
                "        return adj_rec"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "5ce225f9",
            "metadata": {
                "id": "5ce225f9"
            },
            "outputs": [],
            "source": [
                "vgae_model = VGAEModel(\n",
                "    in_feats,\n",
                "    n_hidden,\n",
                "    output_dim\n",
                ")\n",
                "\n",
                "pred = DotPredictor()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "aaf5ef5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "vgae_model = vgae_model.to(device)\n",
                "pred = pred.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88ceeab3",
            "metadata": {
                "id": "88ceeab3"
            },
            "source": [
                "### Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "c945ab1f",
            "metadata": {
                "id": "c945ab1f",
                "outputId": "9c5cda5f-00ff-4baf-be18-8a3b66dd1146"
            },
            "outputs": [{
                "ename": "OutOfMemoryError",
                "evalue": "CUDA out of memory. Tried to allocate 2.41 GiB (GPU 0; 6.00 GiB total capacity; 2.56 GiB already allocated; 1.59 GiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
                "output_type": "error",
                "traceback": [
                    "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                    "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
                    "\u001b[1;32mc:\\Users\\samue\\OneDrive - HKUST Connect\\Year 3 Fall\\COMP 4222\\project\\COMP-4222-Project\\VGAE.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(itertools\u001b[39m.\u001b[39mchain(vgae_model\u001b[39m.\u001b[39mparameters(), pred\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     h \u001b[39m=\u001b[39m vgae_model(train_g\u001b[39m.\u001b[39;49mto(device), train_g\u001b[39m.\u001b[39;49mndata[\u001b[39m'\u001b[39;49m\u001b[39mfeat\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     pos_score \u001b[39m=\u001b[39m pred(train_pos_g\u001b[39m.\u001b[39mto(device), h\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     neg_score \u001b[39m=\u001b[39m pred(train_neg_g\u001b[39m.\u001b[39mto(device), h\u001b[39m.\u001b[39mto(device))\n",
                    "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\envs\\COMP4222\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                    "\u001b[1;32mc:\\Users\\samue\\OneDrive - HKUST Connect\\Year 3 Fall\\COMP 4222\\project\\COMP-4222-Project\\VGAE.ipynb Cell 19\u001b[0m in \u001b[0;36mVGAEModel.forward\u001b[1;34m(self, g, features)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, g, features):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(g, features)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     adj_rec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(z)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m adj_rec\n",
                    "\u001b[1;32mc:\\Users\\samue\\OneDrive - HKUST Connect\\Year 3 Fall\\COMP 4222\\project\\COMP-4222-Project\\VGAE.ipynb Cell 19\u001b[0m in \u001b[0;36mVGAEModel.decoder\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecoder\u001b[39m(\u001b[39mself\u001b[39m, z):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     adj_rec \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mReLU()(torch\u001b[39m.\u001b[39;49mmatmul(z, z\u001b[39m.\u001b[39;49mt()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive%20-%20HKUST%20Connect/Year%203%20Fall/COMP%204222/project/COMP-4222-Project/VGAE.ipynb#X23sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m adj_rec\n",
                    "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\envs\\COMP4222\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                    "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\envs\\COMP4222\\lib\\site-packages\\torch\\nn\\modules\\activation.py:102\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
                    "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\envs\\COMP4222\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
                    "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.41 GiB (GPU 0; 6.00 GiB total capacity; 2.56 GiB already allocated; 1.59 GiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
                ]
            }],
            "source": [
                "import itertools\n",
                "\n",
                "train_loss, val_loss = [], []\n",
                "train_AUC, val_AUC = [], []\n",
                "stop = 0\n",
                "\n",
                "optimizer = torch.optim.Adam(itertools.chain(vgae_model.parameters(), pred.parameters()), lr=0.05)\n",
                "\n",
                "for e in range(500):\n",
                "    # forward\n",
                "    h = vgae_model(train_g.to(device), train_g.ndata['feat'].float().to(device))\n",
                "    pos_score = pred(train_pos_g.to(device), h.to(device))\n",
                "    neg_score = pred(train_neg_g.to(device), h.to(device))\n",
                "    loss = compute_loss(pos_score, neg_score)\n",
                "    train_loss.append(loss.item())\n",
                "    train_AUC.append(compute_auc(pos_score, neg_score))\n",
                "\n",
                "    # backward\n",
                "    optimizer.zero_grad()\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "\n",
                "    # validation\n",
                "    v_pos_score = pred(val_pos_g.to(device), h.to(device))\n",
                "    v_neg_score = pred(val_neg_g.to(device), h.to(device))\n",
                "    v_loss = compute_loss(v_pos_score, v_neg_score)\n",
                "    val_loss.append(v_loss.item())\n",
                "    val_AUC.append(compute_auc(v_pos_score, v_neg_score))\n",
                "\n",
                "    #verbose\n",
                "    if e % 1 == 0:\n",
                "        print('Epoch: {} \\t Train loss: {} \\t Val loss: {} \\t Train AUC: {} \\t Val AUC: {}'.format(e, round(loss.item(), 3), round(v_loss.item(), 3), round(train_AUC[-1],3), round(val_AUC[-1], 3)))\n",
                "\n",
                "\n",
                "    # early stopping\n",
                "    if e > 10:\n",
                "        if v_loss.item() > sum(val_loss[-5:])/5:\n",
                "            stop += 1\n",
                "        else: \n",
                "            stop = 0\n",
                "        if stop >= early_stopping:\n",
                "            print(\"Early Stopped at Epoch {}\".format(e))\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa25daee",
            "metadata": {
                "id": "fa25daee",
                "outputId": "f77fc419-263b-4ee6-abc7-cff09776a0c7"
            },
            "outputs": [],
            "source": [
                "# testing AUC\n",
                "with torch.no_grad():\n",
                "    pos_score = pred(test_pos_g, h)\n",
                "    neg_score = pred(test_neg_g, h)\n",
                "    print('AUC:', compute_auc(pos_score, neg_score))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9fbdf7c9",
            "metadata": {
                "id": "9fbdf7c9"
            },
            "source": [
                "### Result Plotting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbe7e9cd",
            "metadata": {
                "id": "dbe7e9cd",
                "outputId": "b2465fd8-05ef-4f67-92c5-041796a01808"
            },
            "outputs": [],
            "source": [
                "plt.plot(train_loss[50:])\n",
                "plt.plot(val_loss[50:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85db07e4",
            "metadata": {
                "id": "85db07e4",
                "outputId": "4d6ff091-19b0-445d-a454-cb341d7f3105"
            },
            "outputs": [],
            "source": [
                "plt.plot(train_AUC)\n",
                "plt.plot(val_AUC)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c6f53aba",
            "metadata": {
                "id": "c6f53aba"
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.10"
        },
        "vscode": {
            "interpreter": {
                "hash": "eda238182c1de36151cdce09aa997c6697b1a1e480bed704816dfcebedb6bbfe"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}