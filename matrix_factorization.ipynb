{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://everdark.github.io/k9/notebooks/ml/matrix_factorization/matrix_factorization.nb.html#22_binary_matrix_factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparmeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .0003\n",
    "l2 = .04\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_startups = pd.read_csv('./data/startups_formatted.csv')\n",
    "df_investors = pd.read_csv('./data/investors_formatted.csv')\n",
    "df_investments = pd.read_csv('./data/funding_round_formatted.csv')\n",
    "# dummy \n",
    "df_investments[\"X\"] = [\"X\"] * len(df_investments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: 1 is have link, 0 is missing (to be predicted), -1 is no link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_ele(ele):\n",
    "    '''20% to 0, 80% to -1'''\n",
    "    choices = [-1]*8 + [0]*2\n",
    "    if ele == 0:\n",
    "        return random.choice(choices)\n",
    "    else:\n",
    "        return ele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(series):\n",
    "    return [split_ele(i) for i in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starup-Investor Matrix \n",
    "startup_investor_matrix = df_investments.pivot_table(index='funded_object_id', columns='investor_object_id',\n",
    "               values='X', aggfunc='count', fill_value=0)\n",
    "\n",
    "#startup_investor_matrix = startup_investor_matrix.apply(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Startup feature Matrix\n",
    "P = df_startups.loc[startup_investor_matrix.index].iloc[:, 2:].values\n",
    "# Investor feature Matrix\n",
    "Q = np.pad(df_investors.iloc[:, 2:].to_numpy(), [(0,0),(0,120)])\n",
    "\n",
    "startup_investor_matrix = startup_investor_matrix.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17852, 7594), (17852, 221), (7594, 221))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_investor_matrix.shape, P.shape, Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "  def __init__(self, R, P, Q, lr=lr, l2=l2, seed=seed):\n",
    "    self.R = tf.convert_to_tensor(R, dtype=tf.float32)\n",
    "    self.mask = tf.not_equal(self.R, 0)\n",
    "    self.m, self.n = R.shape\n",
    "    self.lr = lr\n",
    "    self.l2 = l2\n",
    "    self.tol = .001\n",
    "    # Initialize trainable weights.\n",
    "    self.weight_init = tf.random_normal_initializer(seed=seed)\n",
    "    self.P = tf.Variable(P, dtype=tf.float32)\n",
    "    self.Q = tf.Variable(Q, dtype=tf.float32)\n",
    "\n",
    "  def loss(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def grad_update(self):\n",
    "    with tf.GradientTape() as t:\n",
    "      t.watch([self.P, self.Q])\n",
    "      self.current_loss = self.loss()\n",
    "    gP, gQ = t.gradient(self.current_loss, [self.P, self.Q])\n",
    "    self.P.assign_sub(self.lr * gP)\n",
    "    self.Q.assign_sub(self.lr * gQ)\n",
    "\n",
    "  def train(self, n_epoch=3000):\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "      if self.current_loss < self.tol:\n",
    "        break\n",
    "\n",
    "class BinaryMF(MatrixFactorization):\n",
    "  def train(self, n_epoch=3000):\n",
    "    # Cast 1/-1 as binary encoding of 0/1.\n",
    "    self.labels = tf.cast(tf.not_equal(tf.boolean_mask(self.R, self.mask), -1), dtype=tf.float32)\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "      if epoch % 50 == 0:\n",
    "        print(epoch, \"\\t\\t\", self.current_loss)\n",
    "\n",
    "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
    "  # We only need scores for non-missing entries.\n",
    "  # The code is hence for educational purpose only.\n",
    "  def loss(self):\n",
    "    \"\"\"Cross entropy loss.\"\"\"\n",
    "    logits = tf.boolean_mask(tf.matmul(self.P, self.Q, transpose_b=True), self.mask)\n",
    "    logloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=logits)\n",
    "    mlogloss = tf.reduce_mean(logloss)\n",
    "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
    "    return mlogloss + self.l2 * l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t\t tf.Tensor(4.75237, shape=(), dtype=float32)\n",
      "50 \t\t tf.Tensor(4.749568, shape=(), dtype=float32)\n",
      "100 \t\t tf.Tensor(4.7467685, shape=(), dtype=float32)\n",
      "150 \t\t tf.Tensor(4.7439785, shape=(), dtype=float32)\n",
      "200 \t\t tf.Tensor(4.7411885, shape=(), dtype=float32)\n",
      "250 \t\t tf.Tensor(4.738403, shape=(), dtype=float32)\n",
      "300 \t\t tf.Tensor(4.7356343, shape=(), dtype=float32)\n",
      "350 \t\t tf.Tensor(4.7328715, shape=(), dtype=float32)\n",
      "400 \t\t tf.Tensor(4.7301116, shape=(), dtype=float32)\n",
      "450 \t\t tf.Tensor(4.727355, shape=(), dtype=float32)\n",
      "500 \t\t tf.Tensor(4.724598, shape=(), dtype=float32)\n",
      "550 \t\t tf.Tensor(4.7218447, shape=(), dtype=float32)\n",
      "600 \t\t tf.Tensor(4.719091, shape=(), dtype=float32)\n",
      "650 \t\t tf.Tensor(4.716343, shape=(), dtype=float32)\n",
      "700 \t\t tf.Tensor(4.7135954, shape=(), dtype=float32)\n",
      "750 \t\t tf.Tensor(4.710849, shape=(), dtype=float32)\n",
      "800 \t\t tf.Tensor(4.7081065, shape=(), dtype=float32)\n",
      "850 \t\t tf.Tensor(4.705364, shape=(), dtype=float32)\n",
      "900 \t\t tf.Tensor(4.702625, shape=(), dtype=float32)\n",
      "950 \t\t tf.Tensor(4.699889, shape=(), dtype=float32)\n",
      "1000 \t\t tf.Tensor(4.6971536, shape=(), dtype=float32)\n",
      "1050 \t\t tf.Tensor(4.694421, shape=(), dtype=float32)\n",
      "1100 \t\t tf.Tensor(4.6916885, shape=(), dtype=float32)\n",
      "1150 \t\t tf.Tensor(4.68896, shape=(), dtype=float32)\n",
      "1200 \t\t tf.Tensor(4.6862354, shape=(), dtype=float32)\n",
      "1250 \t\t tf.Tensor(4.683509, shape=(), dtype=float32)\n",
      "1300 \t\t tf.Tensor(4.680788, shape=(), dtype=float32)\n",
      "1350 \t\t tf.Tensor(4.6780677, shape=(), dtype=float32)\n",
      "1400 \t\t tf.Tensor(4.6753497, shape=(), dtype=float32)\n",
      "1450 \t\t tf.Tensor(4.672637, shape=(), dtype=float32)\n",
      "1500 \t\t tf.Tensor(4.6699204, shape=(), dtype=float32)\n",
      "1550 \t\t tf.Tensor(4.667211, shape=(), dtype=float32)\n",
      "1600 \t\t tf.Tensor(4.664502, shape=(), dtype=float32)\n",
      "1650 \t\t tf.Tensor(4.6617956, shape=(), dtype=float32)\n",
      "1700 \t\t tf.Tensor(4.659093, shape=(), dtype=float32)\n",
      "1750 \t\t tf.Tensor(4.6563897, shape=(), dtype=float32)\n",
      "1800 \t\t tf.Tensor(4.653694, shape=(), dtype=float32)\n",
      "1850 \t\t tf.Tensor(4.6509995, shape=(), dtype=float32)\n",
      "1900 \t\t tf.Tensor(4.6483088, shape=(), dtype=float32)\n",
      "1950 \t\t tf.Tensor(4.6456323, shape=(), dtype=float32)\n",
      "2000 \t\t tf.Tensor(4.6429553, shape=(), dtype=float32)\n",
      "2050 \t\t tf.Tensor(4.6402864, shape=(), dtype=float32)\n",
      "2100 \t\t tf.Tensor(4.6376176, shape=(), dtype=float32)\n",
      "2150 \t\t tf.Tensor(4.6349483, shape=(), dtype=float32)\n",
      "2200 \t\t tf.Tensor(4.6322846, shape=(), dtype=float32)\n",
      "2250 \t\t tf.Tensor(4.629617, shape=(), dtype=float32)\n",
      "2300 \t\t tf.Tensor(4.6269584, shape=(), dtype=float32)\n",
      "2350 \t\t tf.Tensor(4.6242986, shape=(), dtype=float32)\n",
      "2400 \t\t tf.Tensor(4.6216397, shape=(), dtype=float32)\n",
      "2450 \t\t tf.Tensor(4.618986, shape=(), dtype=float32)\n",
      "2500 \t\t tf.Tensor(4.6163273, shape=(), dtype=float32)\n",
      "2550 \t\t tf.Tensor(4.613679, shape=(), dtype=float32)\n",
      "2600 \t\t tf.Tensor(4.6110296, shape=(), dtype=float32)\n",
      "2650 \t\t tf.Tensor(4.6083794, shape=(), dtype=float32)\n",
      "2700 \t\t tf.Tensor(4.6057353, shape=(), dtype=float32)\n",
      "2750 \t\t tf.Tensor(4.6030884, shape=(), dtype=float32)\n",
      "2800 \t\t tf.Tensor(4.6004486, shape=(), dtype=float32)\n",
      "2850 \t\t tf.Tensor(4.59781, shape=(), dtype=float32)\n",
      "2900 \t\t tf.Tensor(4.5951705, shape=(), dtype=float32)\n",
      "2950 \t\t tf.Tensor(4.592537, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6343095 , 0.5262393 , 0.5018861 , ..., 0.5015253 , 0.5038488 ,\n",
       "        0.50164855],\n",
       "       [0.58984995, 0.5175127 , 0.50100666, ..., 0.5006924 , 0.5022855 ,\n",
       "        0.50076795],\n",
       "       [0.58833534, 0.5188004 , 0.5021503 , ..., 0.50201315, 0.5033142 ,\n",
       "        0.50209415],\n",
       "       ...,\n",
       "       [0.5932297 , 0.51873016, 0.5018867 , ..., 0.5018798 , 0.5033861 ,\n",
       "        0.5019858 ],\n",
       "       [0.63097733, 0.52629554, 0.50209755, ..., 0.5022282 , 0.5040083 ,\n",
       "        0.5021026 ],\n",
       "       [0.53636205, 0.5071791 , 0.50023425, ..., 0.50012684, 0.5008801 ,\n",
       "        0.5001847 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmf_model = BinaryMF(startup_investor_matrix, P, Q, lr=.03, l2=.0001, seed=seed)\n",
    "bmf_model.train()   # train\n",
    "b_predictions = tf.sigmoid(tf.matmul(bmf_model.P, bmf_model.Q, transpose_b=True)).numpy()   # predict\n",
    "b_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_mask = np.zeros_like(startup_investor_matrix)     # mask to filter non-zero\n",
    "b_mask[startup_investor_matrix.nonzero()] = 1\n",
    "np.round(b_predictions * b_mask, 2)    # contains only mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075085137733652"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_investor_matrix[startup_investor_matrix > 0] = 1\n",
    "roc_auc_score(startup_investor_matrix.flatten(), b_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6343095 , 0.5262393 , 0.5018861 , ..., 0.5015253 , 0.5038488 ,\n",
       "        0.50164855],\n",
       "       [0.58984995, 0.5175127 , 0.50100666, ..., 0.5006924 , 0.5022855 ,\n",
       "        0.50076795],\n",
       "       [0.58833534, 0.5188004 , 0.5021503 , ..., 0.50201315, 0.5033142 ,\n",
       "        0.50209415],\n",
       "       ...,\n",
       "       [0.5932297 , 0.51873016, 0.5018867 , ..., 0.5018798 , 0.5033861 ,\n",
       "        0.5019858 ],\n",
       "       [0.63097733, 0.52629554, 0.50209755, ..., 0.5022282 , 0.5040083 ,\n",
       "        0.5021026 ],\n",
       "       [0.53636205, 0.5071791 , 0.50023425, ..., 0.50012684, 0.5008801 ,\n",
       "        0.5001847 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('COMP4222')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda238182c1de36151cdce09aa997c6697b1a1e480bed704816dfcebedb6bbfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
