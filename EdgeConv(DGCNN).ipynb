{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0cd285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn import EdgeConv\n",
    "from startup_data_set import *\n",
    "from PredictorClasses import *\n",
    "from CustomMetrics import *\n",
    "from CustomUtilities import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24b33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = COMP4222Dataset()\n",
    "g = graph[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0be2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  203,   231,   232,  ...,  5030,  8850, 15490])\n",
      "tensor([17852, 17852, 17852,  ..., 25444, 25444, 25445])\n"
     ]
    }
   ],
   "source": [
    "u,v=g.edges()\n",
    "print(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8eeda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata[\"feat\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "070d72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g, train_pos_g, val_pos_g, test_pos_g = generate_pos_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a08a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_g, val_neg_g, test_neg_g = generate_neg_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7b9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g, train_pos_g, val_pos_g, test_pos_g = train_g.to(device), train_pos_g.to(device), val_pos_g, test_pos_g.to(device)\n",
    "train_neg_g, val_neg_g, test_neg_g = train_neg_g.to(device), val_neg_g.to(device), test_neg_g.to(device)\n",
    "num_nodes = g.num_nodes\n",
    "num_edges = g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa49cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN_Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feat,\n",
    "                 hidden_feat,\n",
    "                 num_hiddern_layers,\n",
    "                 out_feat):\n",
    "        super(DGCNN_Model, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input layer\n",
    "        self.layers.append(EdgeConv(in_feat, hidden_feat))\n",
    "        # hidden layers\n",
    "        for i in range(num_hiddern_layers - 1):\n",
    "            self.layers.append(EdgeConv(hidden_feat, hidden_feat))\n",
    "        # output layer\n",
    "        self.layers.append(EdgeConv(hidden_feat, out_feat))\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        h = features.float()\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h).float()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24665b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dgcnn_model = DGCNN_Model(train_g.ndata[\"feat\"].shape[1],32,2,16)\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(2*h_feats , h_feats).to(torch.float32)\n",
    "        self.W2 = nn.Linear(h_feats, 1).to(torch.float32)\n",
    "\n",
    "    # concat the source and destination node, use mlp to predict the score\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1).to(torch.float32)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h.to(torch.float32)\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "\n",
    "pred = MLPPredictor(16)\n",
    "early_stopping = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "854e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Train loss: 0.691 \t Val loss: 0.69 \t Train AUC: 0.919 \t Val AUC: 0.881\n",
      "Epoch: 10 \t Train loss: 0.665 \t Val loss: 0.665 \t Train AUC: 0.954 \t Val AUC: 0.934\n",
      "Epoch: 20 \t Train loss: 0.605 \t Val loss: 0.608 \t Train AUC: 0.953 \t Val AUC: 0.94\n",
      "Epoch: 30 \t Train loss: 0.487 \t Val loss: 0.499 \t Train AUC: 0.952 \t Val AUC: 0.939\n",
      "Epoch: 40 \t Train loss: 0.356 \t Val loss: 0.392 \t Train AUC: 0.951 \t Val AUC: 0.939\n",
      "Epoch: 50 \t Train loss: 0.281 \t Val loss: 0.356 \t Train AUC: 0.952 \t Val AUC: 0.939\n",
      "Epoch: 60 \t Train loss: 0.268 \t Val loss: 0.385 \t Train AUC: 0.953 \t Val AUC: 0.94\n",
      "Early Stopped at Epoch 60\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "train_AUC, val_AUC = [], []\n",
    "stop = 0\n",
    "ep = 100\n",
    "optimizer = torch.optim.Adam(itertools.chain(dgcnn_model.parameters(), pred.parameters()))\n",
    "\n",
    "for e in range(ep):\n",
    "    # forward\n",
    "    h =  dgcnn_model(train_g, train_g.ndata['feat'].to(torch.float32))\n",
    "    h = h.flatten(1)\n",
    "    pos_score = pred(train_pos_g,h)\n",
    "    neg_score = pred(train_neg_g,h)\n",
    "    \n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    train_loss.append(loss.item())\n",
    "    train_AUC.append(compute_auc(pos_score, neg_score))\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    v_pos_score = pred(val_pos_g, h)\n",
    "    v_neg_score = pred(val_neg_g, h)\n",
    "    v_loss = compute_loss(v_pos_score, v_neg_score)\n",
    "    val_loss.append(v_loss.item())\n",
    "    val_AUC.append(compute_auc(v_pos_score, v_neg_score))\n",
    "\n",
    "    #verbose\n",
    "    if e % 10 == 0:\n",
    "        print('Epoch: {} \\t Train loss: {} \\t Val loss: {} \\t Train AUC: {} \\t Val AUC: {}'.format(e, round(loss.item(), 3), round(v_loss.item(), 3), round(train_AUC[-1],3), round(val_AUC[-1], 3)))\n",
    "\n",
    "\n",
    "    # early stopping\n",
    "    if e > 10:\n",
    "        if v_loss.item() > sum(val_loss[-5:])/5:\n",
    "            stop += 1\n",
    "        else: \n",
    "            stop = 0\n",
    "        if stop >= early_stopping:\n",
    "            print(\"Early Stopped at Epoch {}\".format(e))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c61ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_ws",
   "language": "python",
   "name": "gnn_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
